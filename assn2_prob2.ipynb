{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Shucen Liu\n",
    "#Assignment 2\n",
    "#CMSC 25025\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import math\n",
    "import numpy as np\n",
    "import json\n",
    "from pprint import pprint\n",
    "import re\n",
    "\n",
    "\n",
    "spark  = SparkSession.builder.master('local').appName('sou').getOrCreate()\n",
    "df = spark.read.json('/project/cmsc25025/sou/speeches.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def collect_words(s):\n",
    "    '''\n",
    "    Convert the speech to a collection of words\n",
    "    '''\n",
    "    s = s.lower().encode('utf-8').translate(string.maketrans(\"\",\"\"), string.punctuation)\n",
    "    return s.split()\n",
    "\n",
    "speech = df.rdd.map(lambda x: (x['president'], x['year'], collect_words(x['text'])))\n",
    "words = speech.map(lambda x: x[2]).reduce(lambda a, b: a + b)\n",
    "words_pool = Counter(words).items()\n",
    "words_pool.sort(key = lambda item: item[1])\n",
    "\n",
    "def find_terms():\n",
    "    '''\n",
    "    Given the word pool, find the terms that appear frequently in the documents \n",
    "    (except the most common 20 words)\n",
    "    '''\n",
    "    terms = []\n",
    "    for word in words_pool[:(len(words_pool) - 20)]:\n",
    "        if word[1] > 50:\n",
    "            terms.append(word[0])\n",
    "    return terms\n",
    "\n",
    "TERMS = find_terms() #The vocabulary that I will use for this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "#(a)\n",
    "def find_frequency(word, word_list):\n",
    "    if word not in word_list:\n",
    "        num_appear = (0, 0) \n",
    "    else:\n",
    "        num_appear = (word_list.count(word), 1)\n",
    "    return num_appear\n",
    "\n",
    "def find_num_doc(word):\n",
    "    num_doc = speech.map(lambda x: whether_exist(word, x[2])).reduce(lambda a, b: a + b)\n",
    "    return num_doc\n",
    "TOTAL = speech.map(lambda x: 1).reduce(lambda a, b: a + b)\n",
    "def find_vector(word_list):\n",
    "    freq_list = []\n",
    "    existence_ls = []\n",
    "    for word in TERMS:\n",
    "        frequency = find_frequency(word, word_list)\n",
    "        freq = float(frequency[0])\n",
    "        existence = float(frequency[1])\n",
    "        freq_list.append(freq)\n",
    "        existence_ls.append(existence)\n",
    "    return freq_list, existence_ls\n",
    "speech_vector_unadj = speech.map(lambda x: (x[0], x[1], find_vector(x[2])[0], find_vector(x[2])[1]))\n",
    "num_appear = speech_vector_unadj.map(lambda x: np.array(x[3])).reduce(lambda x, y: x + y)\n",
    "vector_adj = speech_vector_unadj.map(lambda x: Row(president = x[0], year = x[1], \n",
    "                                    vector = np.array(x[2]) * np.log(TOTAL * np.reciprocal(num_appear))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#(b)\n",
    "pairs = vector_adj.cartesian(vector_adj)\n",
    "def similar_score(x, y):\n",
    "    score = np.dot(x, y)/(np.linalg.norm(x) * np.linalg.norm(y))\n",
    "    return score\n",
    "similarity = pairs.map(lambda x: ((x[0]['president'], x[0]['year']), (x[1]['president'], x[1]['year']), \n",
    "                                  similar_score(x[0]['vector'], x[1]['vector'])))\n",
    "dif_pres = similarity.filter(lambda x: x[0][0] != x[1][0])\n",
    "same_pres = similarity.filter(lambda x: x[0][0] == x[1][0])\n",
    "pres_pairs = dif_pres.map(lambda x: ((x[0], x[1]), (x[2], 1))).reduceByKey(\n",
    "                        lambda a, b: (a[0] + b[0], a[1] + b[1])).mapValues(lambda v: v[0]/v[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#(b)\n",
    "print \"They do not seem very similar to me, I think we also need to consider the order of the words, if we want to have a better similarity measure.\"\n",
    "similar_dif = dif_pres.sortBy(lambda x: x[2], ascending=False).map(lambda x: (x[0], x[1])).take(50)\n",
    "similar_same = same_pres.sortBy(lambda x: x[2], ascending=False).map(lambda x: (x[0], x[1])).take(50)\n",
    "similar_pres = pres_pairs.sortBy(lambda x: x[1], ascending=False).map(lambda x: x[0]).take(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#(c)\n",
    "from pyspark.mllib.clustering import KMeans\n",
    "print \"The clusters kind of make sense, in that same presidents usually lie in the same cluster\"\n",
    "clusters = KMeans.train(vector_adj.map(lambda x: x['vector']), 10, maxIterations=50,\n",
    "initializationMode=\"random\")\n",
    "df_clustered = vector_adj.rdd.map(lambda x: Row(cluster = clusters.predict(x['vector']), president=x['president'], \n",
    "                                                year=x['year']))\n",
    "clusteredschema = spark.createDataFrame(df_clustered)\n",
    "clusteredschema.createOrReplaceTempView(\"clustered_data\")\n",
    "for i in range(0, 10):\n",
    "    query = str(\"SELECT cluster, label FROM clustered_data WHERE cluster = \" + str(i))\n",
    "    cluster = spark.sql(query)\n",
    "    cluster.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
